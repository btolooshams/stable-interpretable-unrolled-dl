{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7WDgTsK55eHt"
   },
   "source": [
    "# Tutorial 1 - Gaussian Image Denoising with Dictionary Learning based Unrolled Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rsDYDMTpEkOY"
   },
   "source": [
    "This tutorial is based on the following paper:\n",
    "\n",
    "B. Tolooshams, and D. Ba, \"[Stable and Interpretable Unrolled Dictionary Learning](https://openreview.net/pdf?id=e3S0Bl2RO8),\" *Transactions on Machine Learning Research*, 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-X17roZV5emn"
   },
   "source": [
    "---\n",
    "\n",
    "## Tutorial objectives \n",
    "\n",
    "In this notebook, we learn how to design and train autoencoders based on dictionary learning for Gaussian image denoising.\n",
    "\n",
    " - Build an unrolled neural network based on dictionary learning model.\n",
    " - Load image data.\n",
    " - Train the network to denoise images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i5L1yMo8Es4q"
   },
   "source": [
    "---\n",
    "## Imports and helper functions\n",
    "\n",
    "Please execute the cell below to initialize the notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1523,
     "status": "ok",
     "timestamp": 1593568559306,
     "user": {
      "displayName": "Bahareh Tolooshams",
      "photoUrl": "",
      "userId": "15522789545155511215"
     },
     "user_tz": 240
    },
    "id": "LybO5Lfh4LLf"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "def compute_psnr(x, xhat):\n",
    "    psnr = []\n",
    "    for i in range(x.shape[0]):\n",
    "        mse = np.mean((x[i] - xhat[i]) ** 2)\n",
    "        max_x = np.max(x[i])\n",
    "        psnr.append(20 * np.log10(max_x) - 10 * np.log10(mse))\n",
    "    return np.mean(psnr)\n",
    "\n",
    "\n",
    "def test_network(data_loader, net, params, name=\"test\"):\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    device = params[\"device\"]\n",
    "\n",
    "    psnr = []\n",
    "    for idx, (x, _) in enumerate(data_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "\n",
    "        # forward\n",
    "        if params[\"noise_std\"]:\n",
    "            x_noisy = (\n",
    "                x + params[\"noise_std\"] / 255 * torch.randn(x.shape, device=device)\n",
    "            ).to(device)\n",
    "            xhat, _ = net(x_noisy)\n",
    "        else:\n",
    "            xhat, _ = net(x)\n",
    "\n",
    "        xhat = torch.clamp(xhat, 0, 1)\n",
    "\n",
    "        psnr.append(\n",
    "            compute_psnr(\n",
    "                x[:, 0].clone().detach().cpu().numpy(),\n",
    "                xhat[:, 0].clone().detach().cpu().numpy(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    psnr = np.mean(np.array(psnr))\n",
    "\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an unrolled network based on a convolutional dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAE(torch.nn.Module):\n",
    "    def __init__(self, params, W=None):\n",
    "        super(CAE, self).__init__()\n",
    "\n",
    "        self.device = params[\"device\"]\n",
    "        self.num_ch = params[\"num_ch\"]\n",
    "        self.lam = params[\"lam\"]\n",
    "        self.num_layers = params[\"num_layers\"]\n",
    "        self.twosided = params[\"twosided\"]\n",
    "        self.num_conv = params[\"num_conv\"]\n",
    "        self.dictionary_dim = params[\"dictionary_dim\"]\n",
    "        self.stride = params[\"stride\"]\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        if W is None:\n",
    "            W = torch.randn(\n",
    "                (self.num_conv, self.num_ch, self.dictionary_dim, self.dictionary_dim),\n",
    "                device=self.device,\n",
    "            )\n",
    "            W = F.normalize(W, p=\"fro\", dim=(-1, -2))\n",
    "            W /= self.num_ch\n",
    "        self.register_parameter(\"W\", torch.nn.Parameter(W))\n",
    "        self.register_buffer(\"step\", torch.tensor(params[\"step\"]))\n",
    "\n",
    "    def get_param(self, name):\n",
    "        return self.state_dict(keep_vars=True)[name]\n",
    "\n",
    "    def normalize(self):\n",
    "        self.W.data = F.normalize(self.W.data, p=\"fro\", dim=(-1, -2))\n",
    "        self.W.data /= self.num_ch\n",
    "\n",
    "    def nonlin(self, z):\n",
    "        if self.twosided:\n",
    "            z = self.relu(torch.abs(z) - self.lam * self.step) * torch.sign(z)\n",
    "        else:\n",
    "            z = self.relu(z - self.lam * self.step)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        zhat = self.nonlin(\n",
    "            F.conv2d(x, self.W, stride=self.stride) * self.step\n",
    "        )\n",
    "        for k in range(self.num_layers - 1):\n",
    "            Wz = F.conv_transpose2d(zhat, self.W, stride=self.stride)\n",
    "            res = Wz - x\n",
    "            grad = F.conv2d(res, self.W, stride=self.stride)\n",
    "            zhat = self.nonlin(zhat - grad * self.step)\n",
    "\n",
    "        xhat = F.conv_transpose2d(zhat, self.W, stride=self.stride)\n",
    "\n",
    "        return xhat, zhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an unrolled network based on a dictionary matrix with learnable bias (lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAElearnbias(torch.nn.Module):\n",
    "    def __init__(self, params, W=None):\n",
    "        super(CAElearnbias, self).__init__()\n",
    "\n",
    "        self.device = params[\"device\"]\n",
    "        self.num_ch = params[\"num_ch\"]\n",
    "        self.num_layers = params[\"num_layers\"]\n",
    "        self.twosided = params[\"twosided\"]\n",
    "        self.num_conv = params[\"num_conv\"]\n",
    "        self.dictionary_dim = params[\"dictionary_dim\"]\n",
    "        self.stride = params[\"stride\"]\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        if W is None:\n",
    "            W = torch.randn(\n",
    "                (self.num_conv, self.num_ch, self.dictionary_dim, self.dictionary_dim),\n",
    "                device=self.device,\n",
    "            )\n",
    "            W = F.normalize(W, p=\"fro\", dim=(-1, -2))\n",
    "            W /= self.num_ch\n",
    "        self.register_parameter(\"W\", torch.nn.Parameter(W))\n",
    "        self.register_buffer(\"step\", torch.tensor(params[\"step\"]))\n",
    "\n",
    "        b = torch.nn.Parameter(\n",
    "            torch.zeros(1, self.num_conv, 1, 1, device=self.device)\n",
    "            + params[\"lam\"] * params[\"step\"]\n",
    "        )\n",
    "        self.register_parameter(\"b\", b)  # this is lam * step\n",
    "\n",
    "    def get_param(self, name):\n",
    "        return self.state_dict(keep_vars=True)[name]\n",
    "\n",
    "    def normalize(self):\n",
    "        self.W.data = F.normalize(self.W.data, p=\"fro\", dim=(-1, -2))\n",
    "        self.W.data /= self.num_ch\n",
    "\n",
    "    def nonlin(self, z):\n",
    "        if self.twosided:\n",
    "            z = self.relu(torch.abs(z) - self.b) * torch.sign(z)\n",
    "        else:\n",
    "            z = self.relu(z - self.b)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        zhat = self.nonlin(\n",
    "            F.conv2d(x, self.W, stride=self.stride) * self.step\n",
    "        )\n",
    "        for k in range(self.num_layers - 1):\n",
    "            Wz = F.conv_transpose2d(zhat, self.W, stride=self.stride)\n",
    "            res = Wz - x\n",
    "            grad = F.conv2d(res, self.W, stride=self.stride)\n",
    "            zhat = self.nonlin(zhat - grad * self.step)\n",
    "\n",
    "        xhat = F.conv_transpose2d(zhat, self.W, stride=self.stride)\n",
    "\n",
    "        return xhat, zhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a relaxed unrolled network based on a dictionary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAElearnbiasuntied(torch.nn.Module):\n",
    "    def __init__(self, params, W=None):\n",
    "        super(CAElearnbiasuntied, self).__init__()\n",
    "\n",
    "        self.device = params[\"device\"]\n",
    "        self.num_ch = params[\"num_ch\"]\n",
    "        self.num_layers = params[\"num_layers\"]\n",
    "        self.twosided = params[\"twosided\"]\n",
    "        self.num_conv = params[\"num_conv\"]\n",
    "        self.dictionary_dim = params[\"dictionary_dim\"]\n",
    "        self.stride = params[\"stride\"]\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        if W is None:\n",
    "            W = torch.randn(\n",
    "                (self.num_conv, self.num_ch, self.dictionary_dim, self.dictionary_dim),\n",
    "                device=self.device,\n",
    "            )\n",
    "            W = F.normalize(W, p=\"fro\", dim=(-1, -2))\n",
    "            W /= self.num_ch\n",
    "        self.register_parameter(\"W\", torch.nn.Parameter(W))\n",
    "\n",
    "        E = torch.clone(W)\n",
    "        D = torch.clone(W)\n",
    "\n",
    "        self.register_parameter(\"E\", torch.nn.Parameter(E))\n",
    "        self.register_parameter(\"D\", torch.nn.Parameter(D))\n",
    "\n",
    "        self.register_buffer(\"step\", torch.tensor(params[\"step\"]))\n",
    "\n",
    "        b = torch.nn.Parameter(\n",
    "            torch.zeros(1, self.num_conv, 1, 1, device=self.device)\n",
    "            + params[\"lam\"] * params[\"step\"]\n",
    "        )\n",
    "        self.register_parameter(\"b\", b)  # this is lam * step\n",
    "\n",
    "    def get_param(self, name):\n",
    "        return self.state_dict(keep_vars=True)[name]\n",
    "\n",
    "    def normalize(self):\n",
    "        self.W.data = F.normalize(self.W.data, p=\"fro\", dim=(-1, -2))\n",
    "        self.W.data /= self.num_ch\n",
    "\n",
    "    def nonlin(self, z):\n",
    "        if self.twosided:\n",
    "            z = self.relu(torch.abs(z) - self.b) * torch.sign(z)\n",
    "        else:\n",
    "            z = self.relu(z - self.b)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        zhat = self.nonlin(\n",
    "            F.conv2d(x, self.E, stride=self.stride) * self.step\n",
    "        )\n",
    "        for k in range(self.num_layers - 1):\n",
    "            Wz = F.conv_transpose2d(zhat, self.D, stride=self.stride)\n",
    "            res = Wz - x\n",
    "            grad = F.conv2d(res, self.E, stride=self.stride)\n",
    "            zhat = self.nonlin(zhat - grad * self.step)\n",
    "\n",
    "        xhat = F.conv_transpose2d(zhat, self.W, stride=self.stride)\n",
    "\n",
    "        return xhat, zhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup network and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"network\": \"CAE\",\n",
    "    \"shuffle\": True,\n",
    "    \"batch_size\": 8,\n",
    "    \"num_workers\": 4,\n",
    "    # related to the Network\n",
    "    \"num_ch\": 1,\n",
    "    \"num_conv\": 64,\n",
    "    \"dictionary_dim\": 9,\n",
    "    \"stride\": 4,\n",
    "    \"patch_size\": 129,\n",
    "    \"lam\": 0.12,\n",
    "    \"step\": 0.1,\n",
    "    \"num_layers\": 15,\n",
    "    \"twosided\": False,\n",
    "    # related to the optimizer\n",
    "    \"lr\": 1e-4,\n",
    "    \"adam_eps\": 1e-3,\n",
    "    \"adam_weight_decay\": 0,\n",
    "    # related to noise\n",
    "    \"noise_std\": 25,\n",
    "    #\n",
    "    \"normalize\": False,\n",
    "    \"num_epochs\": 20,\n",
    "    #\n",
    "    \"tqdm_prints_disable\": False,\n",
    "    \"log_info_epoch_period\": 2,\n",
    "    #\n",
    "    \"train_image_path\": \"../data/CBSD432\",\n",
    "    \"test_image_path\": \"../data/BSD68\",\n",
    "    \"device\": \"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    "}\n",
    "\n",
    "device = params[\"device\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build train and test datasets with various data augmentations from BSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=params[\"train_image_path\"],\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.Grayscale(),\n",
    "            torchvision.transforms.RandomVerticalFlip(),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.RandomCrop(\n",
    "                params[\"patch_size\"],\n",
    "                padding=None,\n",
    "                pad_if_needed=True,\n",
    "                fill=0,\n",
    "                padding_mode=\"constant\",\n",
    "            ),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=params[\"test_image_path\"],\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.Grayscale(),\n",
    "            torchvision.transforms.RandomCrop(\n",
    "                params[\"patch_size\"],\n",
    "                padding=None,\n",
    "                pad_if_needed=True,\n",
    "                fill=0,\n",
    "                padding_mode=\"constant\",\n",
    "            ),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=params[\"shuffle\"],\n",
    "    batch_size=params[\"batch_size\"],\n",
    "    num_workers=params[\"num_workers\"],\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, shuffle=False, batch_size=1, num_workers=params[\"num_workers\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the network (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "if params[\"network\"] == \"CAE\":\n",
    "    net = CAE(params)\n",
    "elif params[\"network\"] == \"CAElearnbias\":\n",
    "    net = CAElearnbias(params)\n",
    "elif params[\"network\"] == \"CAElearnbiasuntied\":\n",
    "    net = CAElearnbiasuntied(params)\n",
    "else:\n",
    "    print(\"Network is not implemented!\")\n",
    "    raise NotImplementedError\n",
    "\n",
    "if params[\"normalize\"]:\n",
    "    net.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    net.parameters(),\n",
    "    lr=params[\"lr\"],\n",
    "    eps=params[\"adam_eps\"],\n",
    "    weight_decay=params[\"adam_weight_decay\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loss criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss criterion\n",
    "# you can also use already defined loss in PyTorch.\n",
    "\n",
    "class DLLoss2D(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DLLoss2D, self).__init__()\n",
    "\n",
    "    def forward(self, x, xhat):\n",
    "        return 0.5 * (x - xhat).pow(2).sum(dim=(-1, -2)).mean()\n",
    "    \n",
    "criterion = DLLoss2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "for epoch in tqdm(\n",
    "    range(params[\"num_epochs\"]), disable=params[\"tqdm_prints_disable\"]\n",
    "):\n",
    "    net.train()\n",
    "\n",
    "    for idx, (x, _) in tqdm(enumerate(train_loader), disable=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(device)\n",
    "\n",
    "        # forward\n",
    "        if params[\"noise_std\"]:\n",
    "            x_noisy = (\n",
    "                x + params[\"noise_std\"] / 255 * torch.randn(x.shape, device=device)\n",
    "            ).to(device)\n",
    "            xhat, zT = net(x_noisy)\n",
    "        else:\n",
    "            xhat, zT = net(x)\n",
    "\n",
    "        loss = criterion(x, xhat)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if params[\"normalize\"]:\n",
    "            net.normalize()\n",
    " \n",
    "    if (epoch + 1) % params[\"log_info_epoch_period\"] == 0:\n",
    "        \n",
    "        test_psnr = test_network(test_loader, net, params)  \n",
    "        \n",
    "        print(\"Epoch: Train loss {}, Test PSNR {}\".format(loss.item(), test_psnr))           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write down your own test and visulization functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7ckUEqdu6Ian",
    "yTlDzIMQ6NzW",
    "ft8fVclW6OHj",
    "cBFb4wdO7umi",
    "o2gNStrC6OKv",
    "xGjLa8GHHAaX",
    "yi3dMjO0HrAq",
    "OKDRh4JnHrMC",
    "VMhzw2pO9csN",
    "IwSu2F_MEVpF",
    "5GXVxCHUEkha",
    "TOgKdxoVE7cW",
    "oXT_PH53FDPR",
    "aZhA92kdFQ-A",
    "GAxLXOlyFlRT",
    "RLyWKXO5vltk",
    "w-bVtLZy4jW-",
    "XpzqF1xl40Dp",
    "fCbI-aWs5NcS",
    "Q0esxRlP5ZHG",
    "poM1zuZC5nqi",
    "OS1vR0C650cF",
    "LVCq4z6_6Tn4"
   ],
   "name": "T3-ae-spikesorting.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
